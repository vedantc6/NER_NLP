{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "The task in NER is to find the entity-type of words. Entities can be locations, time expressions or names.\n",
    "##### Dataset used:\n",
    "Annotated Corpus for NER (https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus/downloads/entity-annotated-corpus.zip/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"entity-annotated-corpus/ner_dataset.csv\", encoding=\"latin1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data is structured by sentences and only has sentence column\n",
    "# filled for the first word, so have to fill nans\n",
    "data = data.fillna(method=\"ffill\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35178"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(data.Word.values))\n",
    "n_words = len(words)\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sentence: 1', 'Sentence: 1', 'Sentence: 1', ...,\n",
       "       'Sentence: 47959', 'Sentence: 47959', 'Sentence: 47959'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentence #\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetSentences():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.n_sent = 1\n",
    "        self.empty = False\n",
    "        \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            sent_num = \"Sentence: {}\".format(self.n_sent)\n",
    "            s = self.data[self.data[\"Sentence #\"] == sent_num]\n",
    "            self.n_sent += 1\n",
    "            return s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist()\n",
    "        except:\n",
    "            self.empty = True\n",
    "            return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_getter = GetSentences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Families', 'of', 'soldiers', 'killed', 'in', 'the', 'conflict', 'joined', 'the', 'protesters', 'who', 'carried', 'banners', 'with', 'such', 'slogans', 'as', '\"', 'Bush', 'Number', 'One', 'Terrorist', '\"', 'and', '\"', 'Stop', 'the', 'Bombings', '.', '\"']\n",
      "['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', 'VBD', 'DT', 'NNS', 'WP', 'VBD', 'NNS', 'IN', 'JJ', 'NNS', 'IN', '``', 'NNP', 'NN', 'CD', 'NN', '``', 'CC', '``', 'VB', 'DT', 'NNS', '.', '``']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sent, pos, tag = sentence_getter.get_next()\n",
    "print(sent); print(pos); print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = data[\"Word\"].values.tolist()\n",
    "tags = data[\"Tag\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memorization\n",
    "Remembering the most common named entity for every word and predicting on that. In case the word is not known, we just predict\n",
    "'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseEstimator provides among other things a default implementation \n",
    "# for the get_params and set_params methods. This is useful to make \n",
    "# the model grid search-able with GridSearchCV for automated \n",
    "# parameters tuning and behave well with others when combined in a \n",
    "# Pipeline.\n",
    "class MemoryTagger(BaseEstimator, TransformerMixin):\n",
    "    # Expects a list of words as X and a list of tags as y\n",
    "    def fit(self, X, y):\n",
    "        voc = {}\n",
    "        self.tags = []\n",
    "        for word, tag in zip(X, y):\n",
    "            if tag not in self.tags:\n",
    "                self.tags.append(tag)\n",
    "            if word in voc:\n",
    "                if tag in voc[word]:\n",
    "                    voc[word][tag] += 1\n",
    "                else:\n",
    "                    voc[word][tag] = 1\n",
    "            else:\n",
    "                voc[word] = {tag: 1}\n",
    "        self.memory = {}\n",
    "        for k, d in voc.items():\n",
    "            self.memory[k] = max(d, key=d.get)\n",
    "    \n",
    "    # Predicts the tag from self.memory\n",
    "    def predict(self, X, y=None):\n",
    "        return [self.memory.get(x, 'O') for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = MemoryTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-per',\n",
       " 'I-geo',\n",
       " 'B-org',\n",
       " 'I-org',\n",
       " 'B-tim',\n",
       " 'B-art',\n",
       " 'I-art',\n",
       " 'I-per',\n",
       " 'I-gpe',\n",
       " 'I-tim',\n",
       " 'B-nat',\n",
       " 'B-eve',\n",
       " 'I-eve',\n",
       " 'I-nat']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.fit(words, tags)\n",
    "tagger.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(estimator=MemoryTagger(), \n",
    "                      X=words, \n",
    "                      y=tags, \n",
    "                      cv=5,\n",
    "                      n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.20      0.05      0.09       402\n",
      "       B-eve       0.54      0.25      0.34       308\n",
      "       B-geo       0.78      0.85      0.81     37644\n",
      "       B-gpe       0.94      0.93      0.94     15870\n",
      "       B-nat       0.42      0.28      0.33       201\n",
      "       B-org       0.67      0.49      0.56     20143\n",
      "       B-per       0.78      0.65      0.71     16990\n",
      "       B-tim       0.87      0.77      0.82     20333\n",
      "       I-art       0.04      0.01      0.01       297\n",
      "       I-eve       0.39      0.12      0.18       253\n",
      "       I-geo       0.73      0.58      0.65      7414\n",
      "       I-gpe       0.62      0.45      0.52       198\n",
      "       I-nat       0.00      0.00      0.00        51\n",
      "       I-org       0.69      0.53      0.60     16784\n",
      "       I-per       0.73      0.65      0.69     17251\n",
      "       I-tim       0.58      0.13      0.21      6528\n",
      "           O       0.97      0.99      0.98    887908\n",
      "\n",
      "   micro avg       0.95      0.95      0.95   1048575\n",
      "   macro avg       0.59      0.45      0.50   1048575\n",
      "weighted avg       0.94      0.95      0.94   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recall suffers since we cannot predict on words we do not know\n",
    "# as of now\n",
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Approach\n",
    "Data is converted to a simple feature vector for every word and then a random forest is used to classify the words. Not all words might be unique in this basic feature vector conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_map(word):\n",
    "    return np.array([word.istitle(), word.islower(), word.isupper(),\n",
    "                    word.isdigit(), word.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_feature_words = [feature_map(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(estimator=RandomForestClassifier(n_estimators=20),\n",
    "                        X=simple_feature_words, y=tags, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedantc6/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00       402\n",
      "       B-eve       0.00      0.00      0.00       308\n",
      "       B-geo       0.64      0.09      0.16     37644\n",
      "       B-gpe       0.00      0.00      0.00     15870\n",
      "       B-nat       0.00      0.00      0.00       201\n",
      "       B-org       0.69      0.15      0.25     20143\n",
      "       B-per       0.70      0.20      0.31     16990\n",
      "       B-tim       0.00      0.00      0.00     20333\n",
      "       I-art       0.00      0.00      0.00       297\n",
      "       I-eve       0.00      0.00      0.00       253\n",
      "       I-geo       0.00      0.00      0.00      7414\n",
      "       I-gpe       0.00      0.00      0.00       198\n",
      "       I-nat       0.00      0.00      0.00        51\n",
      "       I-org       0.00      0.00      0.00     16784\n",
      "       I-per       0.46      0.01      0.02     17251\n",
      "       I-tim       0.00      0.00      0.00      6528\n",
      "           O       0.86      1.00      0.92    887908\n",
      "\n",
      "   micro avg       0.85      0.85      0.85   1048575\n",
      "   macro avg       0.20      0.09      0.10   1048575\n",
      "weighted avg       0.78      0.85      0.80   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Poor because features created hold no information about the words\n",
    "rf_report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(rf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
